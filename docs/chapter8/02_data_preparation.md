# ç¬¬äºŒèŠ‚ æ•°æ®å‡†å¤‡æ¨¡å—å®ç°

RAGç³»ç»Ÿçš„æ•ˆæœå¾ˆå¤§ç¨‹åº¦ä¸Šå–å†³äºæ•°æ®å‡†å¤‡çš„è´¨é‡ã€‚åœ¨ä¸Šä¸€èŠ‚ä¸­ï¼Œæˆ‘ä»¬æ˜ç¡®äº†"å°å—æ£€ç´¢ï¼Œå¤§å—ç”Ÿæˆ"çš„çˆ¶å­æ–‡æœ¬å—ç­–ç•¥ã€‚æ¥ä¸‹æ¥å­¦ä¹ å¦‚ä½•å°†æ•°æ®å‡†å¤‡éƒ¨åˆ†çš„æ¶æ„æ€æƒ³è½¬åŒ–ä¸ºå¯è¿è¡Œçš„ä»£ç ã€‚

```mermaid
flowchart LR
    %% æ•°æ®å‡†å¤‡æ¨¡å—æµç¨‹
    START[ğŸ“ åŠ è½½Markdownæ–‡ä»¶] --> ENHANCE[ğŸ”§ å…ƒæ•°æ®å¢å¼º]
    ENHANCE --> SPLIT[âœ‚ï¸ æŒ‰æ ‡é¢˜åˆ†å—]
    SPLIT --> RELATION[ğŸ·ï¸ çˆ¶å­å…³ç³»å»ºç«‹]
    RELATION --> DEDUP[ğŸ§  æ™ºèƒ½å»é‡æœºåˆ¶]
    DEDUP --> OUTPUT[ğŸ“¦ è¾“å‡ºæ–‡æœ¬å—chunks]
    
    %% å­æµç¨‹è¯¦ç»†è¯´æ˜
    subgraph LoadProcess [æ–‡æ¡£åŠ è½½è¿‡ç¨‹]
        L1[ğŸ“‚ é€’å½’æŸ¥æ‰¾mdæ–‡ä»¶]
        L2[ğŸ“„ è¯»å–æ–‡ä»¶å†…å®¹]
        L3[ğŸ†” åˆ†é…çˆ¶æ–‡æ¡£ID]
        L1 --> L2 --> L3
    end
    
    subgraph EnhanceProcess [å…ƒæ•°æ®å¢å¼ºè¿‡ç¨‹]
        E1[ğŸ·ï¸ æå–èœå“åˆ†ç±»]
        E2[ğŸ“ æå–èœå“åç§°]
        E3[â­ åˆ†æéš¾åº¦ç­‰çº§]
        E1 --> E2 --> E3
    end
    
    subgraph SplitProcess [ç»“æ„åˆ†å—è¿‡ç¨‹]
        S1[ä¸€çº§æ ‡é¢˜åˆ†å‰²]
        S2[äºŒçº§æ ‡é¢˜åˆ†å‰²]
        S3[ä¸‰çº§æ ‡é¢˜åˆ†å‰²]
        S1 --> S2 --> S3
    end
    
    %% è¿æ¥å­æµç¨‹
    START -.-> LoadProcess
    ENHANCE -.-> EnhanceProcess
    SPLIT -.-> SplitProcess
    
    %% æ ·å¼å®šä¹‰
    classDef process fill:#e8f5e8,stroke:#1b5e20,stroke-width:2px
    classDef subprocess fill:#f1f8e9,stroke:#33691e,stroke-width:2px
    classDef output fill:#e1f5fe,stroke:#0277bd,stroke-width:2px
    
    %% åº”ç”¨æ ·å¼
    class START,ENHANCE,SPLIT,RELATION,DEDUP process
    class LoadProcess,EnhanceProcess,SplitProcess subprocess
    class OUTPUT output
```

## ä¸€ã€æ ¸å¿ƒè®¾è®¡

æ•°æ®å‡†å¤‡æ¨¡å—çš„æ ¸å¿ƒæ˜¯å®ç°"å°å—æ£€ç´¢ï¼Œå¤§å—ç”Ÿæˆ"çš„çˆ¶å­æ–‡æœ¬å—æ¶æ„ã€‚

**çˆ¶å­æ–‡æœ¬å—æ˜ å°„å…³ç³»**ï¼š
```
çˆ¶æ–‡æ¡£ï¼ˆå®Œæ•´èœè°±ï¼‰
â”œâ”€â”€ å­å—1ï¼šèœå“ä»‹ç» + éš¾åº¦è¯„çº§
â”œâ”€â”€ å­å—2ï¼šå¿…å¤‡åŸæ–™å’Œå·¥å…·
â”œâ”€â”€ å­å—3ï¼šè®¡ç®—ï¼ˆç”¨é‡é…æ¯”ï¼‰
â”œâ”€â”€ å­å—4ï¼šæ“ä½œï¼ˆåˆ¶ä½œæ­¥éª¤ï¼‰
â””â”€â”€ å­å—5ï¼šé™„åŠ å†…å®¹ï¼ˆå˜åŒ–åšæ³•ï¼‰
```

**åŸºæœ¬æµç¨‹**ï¼š
- **æ£€ç´¢é˜¶æ®µ**ï¼šä½¿ç”¨å°çš„å­å—è¿›è¡Œç²¾ç¡®åŒ¹é…ï¼Œæé«˜æ£€ç´¢å‡†ç¡®æ€§
- **ç”Ÿæˆé˜¶æ®µ**ï¼šä¼ é€’å®Œæ•´çš„çˆ¶æ–‡æ¡£ç»™LLMï¼Œç¡®ä¿ä¸Šä¸‹æ–‡å®Œæ•´æ€§
- **æ™ºèƒ½å»é‡**ï¼šå½“æ£€ç´¢åˆ°åŒä¸€é“èœçš„å¤šä¸ªå­å—æ—¶ï¼Œåˆå¹¶ä¸ºä¸€ä¸ªå®Œæ•´èœè°±

**å…ƒæ•°æ®å¢å¼º**ï¼š
- **èœå“åˆ†ç±»**ï¼šä»æ–‡ä»¶è·¯å¾„æ¨æ–­ï¼ˆè¤èœã€ç´ èœã€æ±¤å“ç­‰ï¼‰
- **éš¾åº¦ç­‰çº§**ï¼šä»å†…å®¹ä¸­çš„æ˜Ÿçº§æ ‡è®°æå–
- **èœå“åç§°**ï¼šä»æ–‡ä»¶åæå–
- **æ–‡æ¡£å…³ç³»**ï¼šå»ºç«‹çˆ¶å­æ–‡æ¡£çš„IDæ˜ å°„å…³ç³»

## äºŒã€æ¨¡å—å®ç°è¯¦è§£

> [data_preparation.pyå®Œæ•´ä»£ç ](https://github.com/datawhalechina/all-in-rag/blob/main/code/C8/rag_modules/data_preparation.py)

### 2.1 ç±»ç»“æ„è®¾è®¡

```python
class DataPreparationModule:
    """æ•°æ®å‡†å¤‡æ¨¡å— - è´Ÿè´£æ•°æ®åŠ è½½ã€æ¸…æ´—å’Œé¢„å¤„ç†"""

    def __init__(self, data_path: str):
        self.data_path = data_path
        self.documents: List[Document] = []  # çˆ¶æ–‡æ¡£ï¼ˆå®Œæ•´é£Ÿè°±ï¼‰
        self.chunks: List[Document] = []     # å­æ–‡æ¡£ï¼ˆæŒ‰æ ‡é¢˜åˆ†å‰²çš„å°å—ï¼‰
        self.parent_child_map: Dict[str, str] = {}  # å­å—ID -> çˆ¶æ–‡æ¡£IDçš„æ˜ å°„
```

- `documents`: å­˜å‚¨å®Œæ•´çš„èœè°±æ–‡æ¡£ï¼ˆçˆ¶æ–‡æ¡£ï¼‰
- `chunks`: å­˜å‚¨æŒ‰æ ‡é¢˜åˆ†å‰²çš„å°å—ï¼ˆå­æ–‡æ¡£ï¼‰
- `parent_child_map`: ç»´æŠ¤çˆ¶å­å…³ç³»æ˜ å°„

### 2.2 æ–‡æ¡£åŠ è½½å®ç°

#### 2.2.1 æ‰¹é‡åŠ è½½Markdownæ–‡ä»¶

```python
def load_documents(self) -> List[Document]:
    """åŠ è½½æ–‡æ¡£æ•°æ®"""
    documents = []
    data_path_obj = Path(self.data_path)

    for md_file in data_path_obj.rglob("*.md"):
        # è¯»å–æ–‡ä»¶å†…å®¹ï¼Œä¿æŒMarkdownæ ¼å¼
        with open(md_file, 'r', encoding='utf-8') as f:
            content = f.read()

        # ä¸ºæ¯ä¸ªçˆ¶æ–‡æ¡£åˆ†é…å”¯ä¸€ID
        parent_id = str(uuid.uuid4())

        # åˆ›å»ºDocumentå¯¹è±¡
        doc = Document(
            page_content=content,
            metadata={
                "source": str(md_file),
                "parent_id": parent_id,
                "doc_type": "parent"  # æ ‡è®°ä¸ºçˆ¶æ–‡æ¡£
            }
        )
        documents.append(doc)

    # å¢å¼ºæ–‡æ¡£å…ƒæ•°æ®
    for doc in documents:
        self._enhance_metadata(doc)

    self.documents = documents
    return documents
```

- `rglob("*.md")`: é€’å½’æŸ¥æ‰¾æ‰€æœ‰Markdownæ–‡ä»¶
- `parent_id`: ä¸ºæ¯ä¸ªçˆ¶æ–‡æ¡£åˆ†é…å”¯ä¸€IDï¼Œå»ºç«‹çˆ¶å­å…³ç³»çš„å…³é”®
- `doc_type`: æ ‡è®°ä¸º"parent"ï¼Œä¾¿äºåŒºåˆ†çˆ¶å­æ–‡æ¡£

#### 2.2.2 å…ƒæ•°æ®å¢å¼º

```python
def _enhance_metadata(self, doc: Document):
    """å¢å¼ºæ–‡æ¡£å…ƒæ•°æ®"""
    file_path = Path(doc.metadata.get('source', ''))
    path_parts = file_path.parts

    # æå–èœå“åˆ†ç±»
    category_mapping = {
        'meat_dish': 'è¤èœ', 'vegetable_dish': 'ç´ èœ', 'soup': 'æ±¤å“',
        'dessert': 'ç”œå“', 'breakfast': 'æ—©é¤', 'staple': 'ä¸»é£Ÿ',
        'aquatic': 'æ°´äº§', 'condiment': 'è°ƒæ–™', 'drink': 'é¥®å“'
    }

    # ä»æ–‡ä»¶è·¯å¾„æ¨æ–­åˆ†ç±»
    doc.metadata['category'] = 'å…¶ä»–'
    for key, value in category_mapping.items():
        if key in file_path.parts:
            doc.metadata['category'] = value
            break

    # æå–èœå“åç§°
    doc.metadata['dish_name'] = file_path.stem

    # åˆ†æéš¾åº¦ç­‰çº§
    content = doc.page_content
    if 'â˜…â˜…â˜…â˜…â˜…' in content:
        doc.metadata['difficulty'] = 'éå¸¸å›°éš¾'
    elif 'â˜…â˜…â˜…â˜…' in content:
        doc.metadata['difficulty'] = 'å›°éš¾'
    # ... (å…¶ä»–éš¾åº¦ç­‰çº§åˆ¤æ–­)

```

- **åˆ†ç±»æ¨æ–­**: ä»HowToCooké¡¹ç›®çš„ç›®å½•ç»“æ„æ¨æ–­èœå“åˆ†ç±»
- **éš¾åº¦æå–**: ä»å†…å®¹ä¸­çš„æ˜Ÿçº§æ ‡è®°è‡ªåŠ¨æå–éš¾åº¦ç­‰çº§
- **åç§°æå–**: ç›´æ¥ä½¿ç”¨æ–‡ä»¶åä½œä¸ºèœå“åç§°

### 2.3 Markdownç»“æ„åˆ†å—

å°†å®Œæ•´çš„èœè°±æ–‡æ¡£æŒ‰ç…§Markdownæ ‡é¢˜ç»“æ„è¿›è¡Œåˆ†å—ï¼Œå®ç°çˆ¶å­æ–‡æœ¬å—æ¶æ„ã€‚

#### 2.3.1 åˆ†å—ç­–ç•¥

```python
def chunk_documents(self) -> List[Document]:
    """Markdownç»“æ„æ„ŸçŸ¥åˆ†å—"""
    if not self.documents:
        raise ValueError("è¯·å…ˆåŠ è½½æ–‡æ¡£")

    # ä½¿ç”¨Markdownæ ‡é¢˜åˆ†å‰²å™¨
    chunks = self._markdown_header_split()

    # ä¸ºæ¯ä¸ªchunkæ·»åŠ åŸºç¡€å…ƒæ•°æ®
    for i, chunk in enumerate(chunks):
        if 'chunk_id' not in chunk.metadata:
            # å¦‚æœæ²¡æœ‰chunk_idï¼ˆæ¯”å¦‚åˆ†å‰²å¤±è´¥çš„æƒ…å†µï¼‰ï¼Œåˆ™ç”Ÿæˆä¸€ä¸ª
            chunk.metadata['chunk_id'] = str(uuid.uuid4())
        chunk.metadata['batch_index'] = i  # åœ¨å½“å‰æ‰¹æ¬¡ä¸­çš„ç´¢å¼•
        chunk.metadata['chunk_size'] = len(chunk.page_content)

    self.chunks = chunks
    return chunks
```

#### 2.3.2 Markdownæ ‡é¢˜åˆ†å‰²å™¨

```python
def _markdown_header_split(self) -> List[Document]:
    """ä½¿ç”¨Markdownæ ‡é¢˜åˆ†å‰²å™¨è¿›è¡Œç»“æ„åŒ–åˆ†å‰²"""
    # å®šä¹‰è¦åˆ†å‰²çš„æ ‡é¢˜å±‚çº§
    headers_to_split_on = [
        ("#", "ä¸»æ ‡é¢˜"),      # èœå“åç§°
        ("##", "äºŒçº§æ ‡é¢˜"),   # å¿…å¤‡åŸæ–™ã€è®¡ç®—ã€æ“ä½œç­‰
        ("###", "ä¸‰çº§æ ‡é¢˜")   # ç®€æ˜“ç‰ˆæœ¬ã€å¤æ‚ç‰ˆæœ¬ç­‰
    ]

    # åˆ›å»ºMarkdownåˆ†å‰²å™¨
    markdown_splitter = MarkdownHeaderTextSplitter(
        headers_to_split_on=headers_to_split_on,
        strip_headers=False  # ä¿ç•™æ ‡é¢˜ï¼Œä¾¿äºç†è§£ä¸Šä¸‹æ–‡
    )

    all_chunks = []
    for doc in self.documents:
        # å¯¹æ¯ä¸ªæ–‡æ¡£è¿›è¡ŒMarkdownåˆ†å‰²
        md_chunks = markdown_splitter.split_text(doc.page_content)

        # ä¸ºæ¯ä¸ªå­å—å»ºç«‹ä¸çˆ¶æ–‡æ¡£çš„å…³ç³»
        parent_id = doc.metadata["parent_id"]

        for i, chunk in enumerate(md_chunks):
            # ä¸ºå­å—åˆ†é…å”¯ä¸€IDå¹¶å»ºç«‹çˆ¶å­å…³ç³»
            child_id = str(uuid.uuid4())
            chunk.metadata.update(doc.metadata)
            chunk.metadata.update({
                "chunk_id": child_id,
                "parent_id": parent_id,
                "doc_type": "child",  # æ ‡è®°ä¸ºå­æ–‡æ¡£
                "chunk_index": i      # åœ¨çˆ¶æ–‡æ¡£ä¸­çš„ä½ç½®
            })

            # å»ºç«‹çˆ¶å­æ˜ å°„å…³ç³»
            self.parent_child_map[child_id] = parent_id

        all_chunks.extend(md_chunks)

    return all_chunks
```

- **ä¸‰çº§æ ‡é¢˜åˆ†å‰²**: æŒ‰ç…§`#`ã€`##`ã€`###`è¿›è¡Œå±‚çº§åˆ†å‰²
- **ä¿ç•™æ ‡é¢˜**: è®¾ç½®`strip_headers=False`ï¼Œä¿ç•™æ ‡é¢˜ä¿¡æ¯ä¾¿äºç†è§£ä¸Šä¸‹æ–‡
- **çˆ¶å­å…³ç³»**: æ¯ä¸ªå­å—éƒ½è®°å½•å…¶çˆ¶æ–‡æ¡£çš„`parent_id`
- **å”¯ä¸€æ ‡è¯†**: æ¯ä¸ªå­å—éƒ½æœ‰ç‹¬ç«‹çš„`child_id`

#### 2.3.3 åˆ†å—æ•ˆæœç¤ºä¾‹

ä»¥"è¥¿çº¢æŸ¿ç‚’é¸¡è›‹"ä¸ºä¾‹ï¼Œåˆ†å—åçš„æ•ˆæœï¼š

```
åŸæ–‡æ¡£ï¼šè¥¿çº¢æŸ¿ç‚’é¸¡è›‹çš„åšæ³•.md (çˆ¶æ–‡æ¡£)
â”œâ”€â”€ å­å—1ï¼š# è¥¿çº¢æŸ¿ç‚’é¸¡è›‹çš„åšæ³• + ç®€ä»‹ + éš¾åº¦è¯„çº§
â”œâ”€â”€ å­å—2ï¼š## å¿…å¤‡åŸæ–™å’Œå·¥å…· + é£Ÿææ¸…å•
â”œâ”€â”€ å­å—3ï¼š## è®¡ç®— + ç”¨é‡é…æ¯”å…¬å¼
â”œâ”€â”€ å­å—4ï¼š## æ“ä½œ + è¯¦ç»†åˆ¶ä½œæ­¥éª¤
â””â”€â”€ å­å—5ï¼š## é™„åŠ å†…å®¹
```

**åˆ†å—é€»è¾‘**ï¼š
- **å­å—1**: åŒ…å«ä¸€çº§æ ‡é¢˜åŠå…¶ä¸‹çš„æ‰€æœ‰å†…å®¹ï¼ˆç®€ä»‹ã€éš¾åº¦è¯„çº§ï¼‰ï¼Œç›´åˆ°é‡åˆ°ä¸‹ä¸€ä¸ªäºŒçº§æ ‡é¢˜
- **å­å—2-5**: æ¯ä¸ªäºŒçº§æ ‡é¢˜åŠå…¶ä¸‹çš„å†…å®¹å½¢æˆä¸€ä¸ªç‹¬ç«‹å­å—
- **ç²¾ç¡®æ£€ç´¢**: ç”¨æˆ·é—®"éœ€è¦ä»€ä¹ˆé£Ÿæ"æ—¶ï¼Œèƒ½ç²¾ç¡®åŒ¹é…åˆ°å­å—2
- **ä¸Šä¸‹æ–‡å®Œæ•´**: ç”Ÿæˆæ—¶ä¼ é€’å®Œæ•´çš„çˆ¶æ–‡æ¡£ï¼ŒåŒ…å«æ‰€æœ‰å¿…è¦ä¿¡æ¯

### 2.4 æ™ºèƒ½å»é‡

å½“ç”¨æˆ·è¯¢é—®"å®«ä¿é¸¡ä¸æ€ä¹ˆåš"æ—¶ï¼Œå¯èƒ½ä¼šæ£€ç´¢åˆ°åŒä¸€é“èœçš„å¤šä¸ªå­å—ã€‚æˆ‘ä»¬éœ€è¦æ™ºèƒ½å»é‡ï¼Œé¿å…é‡å¤ä¿¡æ¯ã€‚

```python
def get_parent_documents(self, child_chunks: List[Document]) -> List[Document]:
    """æ ¹æ®å­å—è·å–å¯¹åº”çš„çˆ¶æ–‡æ¡£ï¼ˆæ™ºèƒ½å»é‡ï¼‰"""
    # ç»Ÿè®¡æ¯ä¸ªçˆ¶æ–‡æ¡£è¢«åŒ¹é…çš„æ¬¡æ•°ï¼ˆç›¸å…³æ€§æŒ‡æ ‡ï¼‰
    parent_relevance = {}
    parent_docs_map = {}

    # æ”¶é›†æ‰€æœ‰ç›¸å…³çš„çˆ¶æ–‡æ¡£IDå’Œç›¸å…³æ€§åˆ†æ•°
    for chunk in child_chunks:
        parent_id = chunk.metadata.get("parent_id")
        if parent_id:
            # å¢åŠ ç›¸å…³æ€§è®¡æ•°
            parent_relevance[parent_id] = parent_relevance.get(parent_id, 0) + 1

            # ç¼“å­˜çˆ¶æ–‡æ¡£ï¼ˆé¿å…é‡å¤æŸ¥æ‰¾ï¼‰
            if parent_id not in parent_docs_map:
                for doc in self.documents:
                    if doc.metadata.get("parent_id") == parent_id:
                        parent_docs_map[parent_id] = doc
                        break

    # æŒ‰ç›¸å…³æ€§æ’åºå¹¶æ„å»ºå»é‡åçš„çˆ¶æ–‡æ¡£åˆ—è¡¨
    sorted_parent_ids = sorted(parent_relevance.keys(),
                             key=lambda x: parent_relevance[x], reverse=True)

    # æ„å»ºå»é‡åçš„çˆ¶æ–‡æ¡£åˆ—è¡¨
    parent_docs = []
    for parent_id in sorted_parent_ids:
        if parent_id in parent_docs_map:
            parent_docs.append(parent_docs_map[parent_id])

    return parent_docs
```

**å»é‡é€»è¾‘**ï¼š
1. **ç»Ÿè®¡ç›¸å…³æ€§**: è®¡ç®—æ¯ä¸ªçˆ¶æ–‡æ¡£è¢«åŒ¹é…çš„å­å—æ•°é‡
2. **æŒ‰ç›¸å…³æ€§æ’åº**: åŒ¹é…å­å—è¶Šå¤šçš„èœè°±æ’åè¶Šé å‰
3. **å»é‡è¾“å‡º**: æ¯ä¸ªèœè°±åªè¾“å‡ºä¸€æ¬¡å®Œæ•´æ–‡æ¡£