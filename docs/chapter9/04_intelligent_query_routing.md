# ç¬¬å››èŠ‚ æ™ºèƒ½æŸ¥è¯¢è·¯ç”±ä¸æ£€ç´¢ç­–ç•¥

> ä¸åŒç±»å‹çš„æŸ¥è¯¢éœ€è¦ä¸åŒçš„æ£€ç´¢ç­–ç•¥ã€‚æœ¬èŠ‚å°†è¯¦ç»†ä»‹ç»å¦‚ä½•æ„å»ºæ™ºèƒ½æŸ¥è¯¢è·¯ç”±å™¨ï¼Œå®ç°æŸ¥è¯¢å¤æ‚åº¦åˆ†æå’Œæ£€ç´¢ç­–ç•¥çš„è‡ªåŠ¨é€‰æ‹©ï¼Œä»¥åŠä¸‰ç§æ ¸å¿ƒæ£€ç´¢ç­–ç•¥çš„è®¾è®¡ä¸å®ç°ã€‚

## ä¸€ã€æ™ºèƒ½æŸ¥è¯¢è·¯ç”±å™¨è®¾è®¡

### 1.1 æŸ¥è¯¢è·¯ç”±çš„å¿…è¦æ€§

åœ¨å›¾RAGç³»ç»Ÿä¸­ï¼Œå¯ä»¥å®ç°æ›´å¤šæ ·åŒ–çš„æŸ¥è¯¢ç±»å‹ï¼š

**ç®€å•æŸ¥è¯¢**ï¼š
- "å·èœæœ‰å“ªäº›ï¼Ÿ"
- "å®«ä¿é¸¡ä¸æ€ä¹ˆåšï¼Ÿ"
- "å‡è‚¥èœæ¨è"

**å¤æ‚æ¨ç†æŸ¥è¯¢**ï¼š
- "é€‚åˆç³–å°¿ç—…äººåƒçš„ä½ç³–å·èœæœ‰å“ªäº›ï¼Œå¹¶ä¸”åˆ¶ä½œæ—¶é—´ä¸è¶…è¿‡30åˆ†é’Ÿï¼Ÿ"
- "å¦‚æœæˆ‘åªæœ‰é¸¡è‚‰å’Œè”¬èœï¼Œèƒ½åšä»€ä¹ˆèœï¼Œæœ€å¥½æ˜¯ä¸åŒèœç³»çš„ï¼Ÿ"
- "å“ªäº›èœå¯ä»¥ç”¨è±†è…æ›¿ä»£è‚‰ç±»ï¼Œå¹¶ä¸”ä¿æŒç›¸ä¼¼çš„å£æ„Ÿï¼Ÿ"

**ä¸­ç­‰å¤æ‚æŸ¥è¯¢**ï¼š
- "å®¶å¸¸èœä¸­å“ªäº›é€‚åˆæ–°æ‰‹åˆ¶ä½œï¼Ÿ"
- "æœ‰ä»€ä¹ˆèœå¯ä»¥ç”¨å‰©ä½™çš„åœŸè±†å’Œèƒ¡èåœï¼Ÿ"

ä¸åŒå¤æ‚åº¦çš„æŸ¥è¯¢éœ€è¦ä¸åŒçš„æ£€ç´¢ç­–ç•¥æ¥è·å¾—æœ€ä½³æ•ˆæœã€‚

### 1.2 æŸ¥è¯¢åˆ†ææ¡†æ¶

æ™ºèƒ½æŸ¥è¯¢è·¯ç”±å™¨é€šè¿‡å››ä¸ªç»´åº¦åˆ†ææŸ¥è¯¢ç‰¹å¾ï¼š

```python
class IntelligentQueryRouter:
    def __init__(self, traditional_retrieval, graph_rag_retrieval, llm_client, config):
        self.traditional_retrieval = traditional_retrieval
        self.graph_rag_retrieval = graph_rag_retrieval
        self.llm_client = llm_client
        self.config = config

        # è·¯ç”±ç»Ÿè®¡
        self.route_stats = {
            "traditional_count": 0,
            "graph_rag_count": 0,
            "combined_count": 0,
            "total_queries": 0
        }

    def analyze_query(self, query: str) -> QueryAnalysis:
        """æ·±åº¦åˆ†ææŸ¥è¯¢ç‰¹å¾ï¼Œå†³å®šæœ€ä½³æ£€ç´¢ç­–ç•¥"""

        analysis_prompt = f"""
        ä½œä¸ºRAGç³»ç»Ÿçš„æŸ¥è¯¢åˆ†æä¸“å®¶ï¼Œè¯·æ·±åº¦åˆ†æä»¥ä¸‹æŸ¥è¯¢çš„ç‰¹å¾ï¼š

        æŸ¥è¯¢ï¼š{query}

        è¯·ä»ä»¥ä¸‹ç»´åº¦åˆ†æï¼š

        1. æŸ¥è¯¢å¤æ‚åº¦ (0-1)ï¼š
           - 0.0-0.3: ç®€å•ä¿¡æ¯æŸ¥æ‰¾ï¼ˆå¦‚ï¼šçº¢çƒ§è‚‰æ€ä¹ˆåšï¼Ÿï¼‰
           - 0.4-0.7: ä¸­ç­‰å¤æ‚åº¦ï¼ˆå¦‚ï¼šå·èœæœ‰å“ªäº›ç‰¹è‰²èœï¼Ÿï¼‰
           - 0.8-1.0: é«˜å¤æ‚åº¦æ¨ç†ï¼ˆå¦‚ï¼šä¸ºä»€ä¹ˆå·èœç”¨èŠ±æ¤’è€Œä¸æ˜¯èƒ¡æ¤’ï¼Ÿï¼‰

        2. å…³ç³»å¯†é›†åº¦ (0-1)ï¼š
           - 0.0-0.3: å•ä¸€å®ä½“ä¿¡æ¯ï¼ˆå¦‚ï¼šè¥¿çº¢æŸ¿çš„è¥å…»ä»·å€¼ï¼‰
           - 0.4-0.7: å®ä½“é—´å…³ç³»ï¼ˆå¦‚ï¼šé¸¡è‚‰é…ä»€ä¹ˆè”¬èœï¼Ÿï¼‰
           - 0.8-1.0: å¤æ‚å…³ç³»ç½‘ç»œï¼ˆå¦‚ï¼šå·èœçš„å½¢æˆä¸åœ°ç†ã€å†å²çš„å…³ç³»ï¼‰

        3. æ¨ç†éœ€æ±‚ï¼šæ˜¯å¦éœ€è¦å¤šè·³æ¨ç†ã€å› æœåˆ†æã€å¯¹æ¯”åˆ†æï¼Ÿ
        4. å®ä½“è¯†åˆ«ï¼šæŸ¥è¯¢ä¸­åŒ…å«å¤šå°‘ä¸ªæ˜ç¡®å®ä½“ï¼Ÿ

        åŸºäºåˆ†ææ¨èæ£€ç´¢ç­–ç•¥ï¼š
        - hybrid_traditional: é€‚åˆç®€å•ç›´æ¥çš„ä¿¡æ¯æŸ¥æ‰¾
        - graph_rag: é€‚åˆå¤æ‚å…³ç³»æ¨ç†å’ŒçŸ¥è¯†å‘ç°
        - combined: éœ€è¦ä¸¤ç§ç­–ç•¥ç»“åˆ

        è¿”å›JSONæ ¼å¼ï¼š
        {{
            "query_complexity": 0.6,
            "relationship_intensity": 0.8,
            "reasoning_required": true,
            "entity_count": 3,
            "recommended_strategy": "graph_rag",
            "confidence": 0.85,
            "reasoning": "è¯¥æŸ¥è¯¢æ¶‰åŠå¤šä¸ªå®ä½“é—´çš„å¤æ‚å…³ç³»ï¼Œéœ€è¦å›¾ç»“æ„æ¨ç†"
        }}
        """

        try:
            response = self.llm_client.chat.completions.create(
                model=self.config.llm_model,
                messages=[{"role": "user", "content": analysis_prompt}],
                temperature=0.1,
                max_tokens=800
            )

            result = json.loads(response.choices[0].message.content.strip())

            # æ„å»ºQueryAnalysiså¯¹è±¡
            analysis = QueryAnalysis(
                query_complexity=result.get("query_complexity", 0.5),
                relationship_intensity=result.get("relationship_intensity", 0.5),
                reasoning_required=result.get("reasoning_required", False),
                entity_count=result.get("entity_count", 1),
                recommended_strategy=SearchStrategy(result.get("recommended_strategy", "hybrid_traditional")),
                confidence=result.get("confidence", 0.5),
                reasoning=result.get("reasoning", "é»˜è®¤åˆ†æ")
            )

            return analysis

        except Exception as e:
            logger.error(f"æŸ¥è¯¢åˆ†æå¤±è´¥: {e}")
            # é™çº§æ–¹æ¡ˆï¼šåŸºäºè§„åˆ™çš„ç®€å•åˆ†æ
            return self._rule_based_analysis(query)
```

### 1.3 è§„åˆ™åŸºç¡€çš„é™çº§åˆ†æ

å½“LLMåˆ†æå¤±è´¥æ—¶ï¼Œä½¿ç”¨åŸºäºè§„åˆ™çš„é™çº§åˆ†æï¼š

```python
def _rule_based_analysis(self, query: str) -> QueryAnalysis:
    """åŸºäºè§„åˆ™çš„é™çº§åˆ†æ"""
    # ç®€å•çš„è§„åˆ™åˆ¤æ–­
    complexity_keywords = ["ä¸ºä»€ä¹ˆ", "å¦‚ä½•", "å…³ç³»", "å½±å“", "åŸå› ", "æ¯”è¾ƒ", "åŒºåˆ«"]
    relation_keywords = ["é…", "æ­é…", "ç»„åˆ", "ç›¸å…³", "è”ç³»", "è¿æ¥"]

    complexity = sum(1 for kw in complexity_keywords if kw in query) / len(complexity_keywords)
    relation_intensity = sum(1 for kw in relation_keywords if kw in query) / len(relation_keywords)

    # ç­–ç•¥é€‰æ‹©
    if complexity > 0.3 or relation_intensity > 0.3:
        strategy = SearchStrategy.GRAPH_RAG
    else:
        strategy = SearchStrategy.HYBRID_TRADITIONAL

    return QueryAnalysis(
        query_complexity=complexity,
        relationship_intensity=relation_intensity,
        reasoning_required=complexity > 0.3,
        entity_count=len(query.split()),  # ç®€å•ä¼°ç®—
        recommended_strategy=strategy,
        confidence=0.6,
        reasoning="åŸºäºè§„åˆ™çš„ç®€å•åˆ†æ"
    )
```

### 1.4 æ™ºèƒ½è·¯ç”±æ‰§è¡Œ

åŸºäºåˆ†æç»“æœï¼Œè·¯ç”±åˆ°æœ€é€‚åˆçš„æ£€ç´¢ç­–ç•¥ï¼š

```python
def route_query(self, query: str, top_k: int = 5) -> Tuple[List[Document], QueryAnalysis]:
    """æ™ºèƒ½è·¯ç”±æŸ¥è¯¢åˆ°æœ€é€‚åˆçš„æ£€ç´¢å¼•æ“"""
    logger.info(f"å¼€å§‹æ™ºèƒ½è·¯ç”±: {query}")

    # 1. åˆ†ææŸ¥è¯¢ç‰¹å¾
    analysis = self.analyze_query(query)

    # 2. æ›´æ–°ç»Ÿè®¡
    self._update_route_stats(analysis.recommended_strategy)

    # 3. æ ¹æ®ç­–ç•¥æ‰§è¡Œæ£€ç´¢
    try:
        if analysis.recommended_strategy == SearchStrategy.HYBRID_TRADITIONAL:
            logger.info("ä½¿ç”¨ä¼ ç»Ÿæ··åˆæ£€ç´¢")
            documents = self.traditional_retrieval.hybrid_search(query, top_k)

        elif analysis.recommended_strategy == SearchStrategy.GRAPH_RAG:
            logger.info("ğŸ•¸ï¸ ä½¿ç”¨å›¾RAGæ£€ç´¢")
            documents = self.graph_rag_retrieval.graph_rag_search(query, top_k)

        elif analysis.recommended_strategy == SearchStrategy.COMBINED:
            logger.info("ğŸ”„ ä½¿ç”¨ç»„åˆæ£€ç´¢ç­–ç•¥")
            documents = self._combined_search(query, top_k)

        # 4. ç»“æœåå¤„ç†
        documents = self._post_process_results(documents, analysis)

        return documents, analysis

    except Exception as e:
        logger.error(f"æŸ¥è¯¢è·¯ç”±å¤±è´¥: {e}")
        # é™çº§åˆ°ä¼ ç»Ÿæ£€ç´¢
        documents = self.traditional_retrieval.hybrid_search(query, top_k)
        return documents, analysis

def _combined_search(self, query: str, top_k: int) -> List[Document]:
    """ç»„åˆæœç´¢ç­–ç•¥ï¼šç»“åˆä¼ ç»Ÿæ£€ç´¢å’Œå›¾RAGçš„ä¼˜åŠ¿"""
    # åˆ†é…ç»“æœæ•°é‡
    traditional_k = max(1, top_k // 2)
    graph_k = top_k - traditional_k

    # æ‰§è¡Œä¸¤ç§æ£€ç´¢
    traditional_docs = self.traditional_retrieval.hybrid_search(query, traditional_k)
    graph_docs = self.graph_rag_retrieval.graph_rag_search(query, graph_k)

    # åˆå¹¶å’Œå»é‡ï¼ˆç®€åŒ–å®ç°ï¼‰
    # ... å…·ä½“çš„åˆå¹¶é€»è¾‘

    return combined_docs
```

## äºŒã€ä¸‰ç§æ£€ç´¢ç­–ç•¥è¯¦è§£

### 2.1 ä¼ ç»Ÿæ··åˆæ£€ç´¢ç­–ç•¥

> [æ··åˆæ£€ç´¢æ¨¡å—ä»£ç ](https://github.com/datawhalechina/all-in-rag/blob/main/code/C9/rag_modules/hybrid_retrieval.py)

é€‚ç”¨äºç®€å•æŸ¥è¯¢ï¼Œç»“åˆåŒå±‚æ£€ç´¢å’Œå‘é‡æ£€ç´¢ï¼š

```python
class HybridRetrievalModule:
    def hybrid_search(self, query: str, top_k: int = 5) -> List[Document]:
        """
        æ··åˆæ£€ç´¢ï¼šä½¿ç”¨Round-robinè½®è¯¢åˆå¹¶ç­–ç•¥
        å…¬å¹³è½®è¯¢åˆå¹¶ä¸åŒæ£€ç´¢ç»“æœï¼Œä¸ä½¿ç”¨æƒé‡é…ç½®
        """
        logger.info(f"å¼€å§‹æ··åˆæ£€ç´¢: {query}")

        # 1. åŒå±‚æ£€ç´¢ï¼ˆå®ä½“+ä¸»é¢˜æ£€ç´¢ï¼‰
        dual_docs = self.dual_level_retrieval(query, top_k)

        # 2. å¢å¼ºå‘é‡æ£€ç´¢
        vector_docs = self.vector_search_enhanced(query, top_k)

        # 3. Round-robinè½®è¯¢åˆå¹¶
        merged_docs = []
        seen_doc_ids = set()
        max_len = max(len(dual_docs), len(vector_docs))

        # Round-robinç­–ç•¥ï¼šäº¤æ›¿ä»ä¸¤ä¸ªç»“æœåˆ—è¡¨ä¸­å–æ–‡æ¡£
        # è¿™ç§æ–¹æ³•ç¡®ä¿äº†ä¸åŒæ£€ç´¢æ–¹æ³•çš„ç»“æœéƒ½èƒ½å¾—åˆ°å…¬å¹³çš„å±•ç¤ºæœºä¼š
        for i in range(max_len):
            # å…ˆæ·»åŠ åŒå±‚æ£€ç´¢ç»“æœ
            if i < len(dual_docs):
                doc = dual_docs[i]
                doc_id = doc.metadata.get("node_id", hash(doc.page_content))
                if doc_id not in seen_doc_ids:
                    seen_doc_ids.add(doc_id)
                    doc.metadata["search_method"] = "dual_level"
                    doc.metadata["final_score"] = doc.metadata.get("relevance_score", 0.0)
                    merged_docs.append(doc)

            # å†æ·»åŠ å‘é‡æ£€ç´¢ç»“æœ
            if i < len(vector_docs):
                doc = vector_docs[i]
                doc_id = doc.metadata.get("node_id", hash(doc.page_content))
                if doc_id not in seen_doc_ids:
                    seen_doc_ids.add(doc_id)
                    doc.metadata["search_method"] = "vector"
                    doc.metadata["final_score"] = doc.metadata.get("relevance_score", 0.0)
                    merged_docs.append(doc)

        return merged_docs[:top_k]
```

**Round-robinè½®è¯¢åˆå¹¶åŸç†**ï¼šRound-robinï¼ˆè½®è¯¢ï¼‰æ˜¯ä¸€ç§å…¬å¹³è°ƒåº¦ç®—æ³•ï¼Œåœ¨RAGç³»ç»Ÿä¸­ç”¨äºèåˆå¤šä¸ªæ£€ç´¢ç»“æœã€‚å…¶æ ¸å¿ƒæ˜¯æŒ‰é¡ºåºè½®æµä»ä¸åŒçš„ç»“æœåˆ—è¡¨ä¸­é€‰æ‹©æ–‡æ¡£ï¼Œè€Œä¸æ˜¯åŸºäºåˆ†æ•°æƒé‡è¿›è¡Œåˆå¹¶ã€‚è¿™ç§æ–¹æ³•ç¡®ä¿äº†æ¯ç§æ£€ç´¢ç­–ç•¥çš„ç»“æœéƒ½èƒ½å¾—åˆ°å…¬å¹³çš„å±•ç¤ºæœºä¼šï¼Œé¿å…äº†æŸç§æ–¹æ³•å› æ’åºé å‰è€Œè¢«è¿‡åº¦é€‰æ‹©çš„é—®é¢˜ã€‚ç›¸æ¯”å¤æ‚çš„åŠ æƒèåˆï¼ŒRound-robinå®ç°ç®€å•ä¸”ç¨³å®šï¼Œæ— éœ€è°ƒä¼˜æƒé‡å‚æ•°ï¼Œè‡ªç„¶ä¿æŒäº†ç»“æœçš„å¤šæ ·æ€§ã€‚

### 2.2 å›¾RAGæ£€ç´¢ç­–ç•¥

> [å›¾RAGæ£€ç´¢æ¨¡å—ä»£ç ](https://github.com/datawhalechina/all-in-rag/blob/main/code/C9/rag_modules/graph_rag_retrieval.py)

é€‚ç”¨äºå¤æ‚æ¨ç†æŸ¥è¯¢ï¼ŒåŸºäºå›¾ç»“æ„è¿›è¡Œå¤šè·³æ¨ç†ï¼š

```python
class GraphRAGRetrieval:
    def graph_rag_search(self, query: str, top_k: int = 5) -> List[Document]:
        """
        å›¾RAGä¸»æœç´¢æ¥å£ï¼šæ•´åˆæ‰€æœ‰å›¾RAGèƒ½åŠ›
        """
        logger.info(f"å¼€å§‹å›¾RAGæ£€ç´¢: {query}")

        # 1. æŸ¥è¯¢æ„å›¾ç†è§£
        graph_query = self.understand_graph_query(query)
        logger.info(f"æŸ¥è¯¢ç±»å‹: {graph_query.query_type.value}")

        results = []

        try:
            # 2. æ ¹æ®æŸ¥è¯¢ç±»å‹æ‰§è¡Œä¸åŒç­–ç•¥
            if graph_query.query_type in [QueryType.MULTI_HOP, QueryType.PATH_FINDING]:
                # å¤šè·³éå†
                paths = self.multi_hop_traversal(graph_query)
                results.extend(self._paths_to_documents(paths, query))

            elif graph_query.query_type == QueryType.SUBGRAPH:
                # å­å›¾æå–
                subgraph = self.extract_knowledge_subgraph(graph_query)

                # å›¾ç»“æ„æ¨ç†
                reasoning_chains = self.graph_structure_reasoning(subgraph, query)

                results.extend(self._subgraph_to_documents(subgraph, reasoning_chains, query))

            elif graph_query.query_type == QueryType.ENTITY_RELATION:
                # å®ä½“å…³ç³»æŸ¥è¯¢
                paths = self.multi_hop_traversal(graph_query)
                results.extend(self._paths_to_documents(paths, query))

            # 3. å›¾ç»“æ„ç›¸å…³æ€§æ’åº
            results = self._rank_by_graph_relevance(results, query)

            return results[:top_k]

        except Exception as e:
            logger.error(f"å›¾RAGæ£€ç´¢å¤±è´¥: {e}")
            return []
```

**å›¾RAGæ£€ç´¢æµç¨‹**ï¼š

```mermaid
flowchart TD
    A[ç”¨æˆ·æŸ¥è¯¢] --> B[æŸ¥è¯¢æ„å›¾ç†è§£]
    B --> C{æŸ¥è¯¢ç±»å‹åˆ¤æ–­}

    C -->|ç®€å•å…³ç³»| D1[å®ä½“å…³ç³»æŸ¥è¯¢]
    C -->|å¤æ‚æ¨ç†| D2[å¤šè·³æ¨ç†æŸ¥è¯¢]
    C -->|çŸ¥è¯†ç½‘ç»œ| D3[å­å›¾æå–æŸ¥è¯¢]

    D1 --> E1[ç›´æ¥å…³ç³»æ£€ç´¢]
    D2 --> E2[å¤šè·³å›¾éå†]
    D3 --> E3[çŸ¥è¯†å­å›¾æå–]

    E1 --> F[ç»“æœè½¬æ¢ä¸æ’åº]
    E2 --> F
    E3 --> F

    F --> G[è¿”å›Top-Kç»“æœ]

    style A fill:#e1f5fe
    style C fill:#fff3e0
    style F fill:#f3e5f5
    style G fill:#e8f5e8
```

**å¤šè·³æ¨ç†**ï¼š

å¤šè·³æ¨ç†æ˜¯æŒ‡é€šè¿‡å›¾ä¸­çš„å¤šä¸ªèŠ‚ç‚¹å’Œå…³ç³»è¿›è¡Œé—´æ¥æ¨ç†ï¼Œè¿™æ˜¯å›¾RAGç›¸æ¯”ä¼ ç»ŸRAGçš„æ ¸å¿ƒä¼˜åŠ¿ã€‚ä¼ ç»Ÿæ£€ç´¢åªèƒ½æ‰¾åˆ°ç›´æ¥åŒ¹é…çš„ä¿¡æ¯ï¼Œè€Œå¤šè·³æ¨ç†èƒ½å¤Ÿå‘ç°æ•°æ®ä¸­çš„éšå«å…³è”ã€‚

- **å·¥ä½œåŸç†**ï¼š
  1. **è·¯å¾„å‘ç°**ï¼šåœ¨çŸ¥è¯†å›¾è°±ä¸­å¯»æ‰¾è¿æ¥èµ·å§‹å®ä½“å’Œç›®æ ‡å®ä½“çš„è·¯å¾„
  2. **å…³ç³»ä¼ é€’**ï¼šé€šè¿‡ä¸­é—´èŠ‚ç‚¹ä¼ é€’è¯­ä¹‰å…³ç³»
  3. **éšå«æ¨ç†**ï¼šå‘ç°åŸå§‹æ•°æ®ä¸­æ²¡æœ‰æ˜ç¡®è¡¨è¾¾çš„çŸ¥è¯†å…³è”

- **å…·ä½“ç¤ºä¾‹**ï¼šç”¨æˆ·é—®"é¸¡è‚‰é…ä»€ä¹ˆè”¬èœå¥½ï¼Ÿ"

  ```
  ä¼ ç»Ÿæ£€ç´¢ï¼šåªèƒ½æ‰¾åˆ°ç›´æ¥æåˆ°"é¸¡è‚‰+è”¬èœ"çš„æ–‡æ¡£ï¼ˆå¯èƒ½å¾ˆå°‘ï¼‰

  å¤šè·³æ¨ç†ï¼š
  1è·³ï¼šé¸¡è‚‰ â†’ å®«ä¿é¸¡ä¸ã€å£æ°´é¸¡ã€ç™½åˆ‡é¸¡...
  2è·³ï¼šå®«ä¿é¸¡ä¸ â†’ èƒ¡èåœã€é’æ¤’ã€èŠ±ç”Ÿç±³...
  3è·³ï¼šèƒ¡èåœ â†’ è”¬èœç±»åˆ«

  æ¨ç†ç»“æœï¼šé¸¡è‚‰ç»å¸¸ä¸èƒ¡èåœã€é’æ¤’ç­‰è”¬èœæ­é…
  ```

- **å¤šè·³æ¨ç†çš„ä»·å€¼**ï¼š
  - **çŸ¥è¯†å‘ç°**ï¼šæŒ–æ˜æ•°æ®ä¸­çš„éšå«å…³ç³»
  - **æ¨èå¢å¼º**ï¼šæä¾›æ›´ä¸°å¯Œçš„æ­é…å»ºè®®
  - **è¯­ä¹‰ç†è§£**ï¼šæ¨¡æ‹Ÿäººç±»çš„è”æƒ³æ€ç»´è¿‡ç¨‹
  - **æ•°æ®åˆ©ç”¨**ï¼šå……åˆ†åˆ©ç”¨å›¾ç»“æ„çš„å…³ç³»ä¿¡æ¯

é€šè¿‡è¿™ç§å¤šè·³éå†ï¼Œç³»ç»Ÿèƒ½å‘ç°"é¸¡è‚‰"å’Œ"èƒ¡èåœ"ä¹‹é—´çš„éšå«å…³ç³»ï¼šå®ƒä»¬ç»å¸¸åœ¨åŒä¸€é“èœä¸­å‡ºç°ï¼Œå³ä½¿åœ¨åŸå§‹æ•°æ®ä¸­æ²¡æœ‰ç›´æ¥çš„"é¸¡è‚‰-èƒ¡èåœ"å…³ç³»ã€‚

### 2.3 ç»„åˆæ£€ç´¢ç­–ç•¥

> [æ™ºèƒ½æŸ¥è¯¢è·¯ç”±å™¨ä»£ç ](https://github.com/datawhalechina/all-in-rag/blob/main/code/C9/rag_modules/intelligent_query_router.py)

é€‚ç”¨äºä¸­ç­‰å¤æ‚æŸ¥è¯¢ï¼Œç»“åˆä¼ ç»Ÿæ£€ç´¢å’Œå›¾RAGçš„ä¼˜åŠ¿ï¼š

```python
def _combined_search(self, query: str, top_k: int) -> List[Document]:
    """ç»„åˆæœç´¢ç­–ç•¥ï¼šç»“åˆä¼ ç»Ÿæ£€ç´¢å’Œå›¾RAGçš„ä¼˜åŠ¿"""
    # åˆ†é…ç»“æœæ•°é‡
    traditional_k = max(1, top_k // 2)
    graph_k = top_k - traditional_k

    # æ‰§è¡Œä¸¤ç§æ£€ç´¢
    traditional_docs = self.traditional_retrieval.hybrid_search(query, traditional_k)
    graph_docs = self.graph_rag_retrieval.graph_rag_search(query, graph_k)

    # Round-robinè½®è¯¢åˆå¹¶ï¼ˆå‚è€ƒLightRAGçš„èåˆç­–ç•¥ï¼‰
    combined_docs = []
    seen_contents = set()

    # äº¤æ›¿æ·»åŠ ç»“æœï¼Œä¿æŒå¤šæ ·æ€§ï¼ˆRound-robinç­–ç•¥ï¼‰
    max_len = max(len(traditional_docs), len(graph_docs))
    for i in range(max_len):
        # æ·»åŠ ä¼ ç»Ÿæ£€ç´¢ç»“æœ
        if i < len(traditional_docs):
            doc = traditional_docs[i]
            if doc.page_content not in seen_contents:
                seen_contents.add(doc.page_content)
                doc.metadata["search_strategy"] = "traditional"
                combined_docs.append(doc)

        # æ·»åŠ å›¾RAGç»“æœ
        if i < len(graph_docs):
            doc = graph_docs[i]
            if doc.page_content not in seen_contents:
                seen_contents.add(doc.page_content)
                doc.metadata["search_strategy"] = "graph_rag"
                combined_docs.append(doc)

    return combined_docs[:top_k]
```

**Round-robinè½®è¯¢åˆå¹¶æœºåˆ¶**ï¼šåœ¨ç»„åˆæ£€ç´¢ä¸­ï¼ŒRound-robinç®—æ³•æŒ‰ç…§å›ºå®šçš„è½®è½¬é¡ºåºä»ä¼ ç»Ÿæ£€ç´¢å’Œå›¾RAGæ£€ç´¢çš„ç»“æœä¸­äº¤æ›¿é€‰æ‹©æ–‡æ¡£ã€‚å…·ä½“è¿‡ç¨‹æ˜¯ï¼šç¬¬1ä¸ªä½ç½®é€‰æ‹©ä¼ ç»Ÿæ£€ç´¢çš„ç¬¬1ä¸ªç»“æœï¼Œç¬¬2ä¸ªä½ç½®é€‰æ‹©å›¾RAGçš„ç¬¬1ä¸ªç»“æœï¼Œç¬¬3ä¸ªä½ç½®é€‰æ‹©ä¼ ç»Ÿæ£€ç´¢çš„ç¬¬2ä¸ªç»“æœï¼Œä»¥æ­¤ç±»æ¨ã€‚è¿™ç§æœºåˆ¶é¿å…äº†å¤æ‚çš„åˆ†æ•°èåˆè®¡ç®—ï¼Œé€šè¿‡ä½ç½®è½®è½¬è‡ªç„¶å®ç°äº†ä¸åŒæ£€ç´¢ç­–ç•¥ç»“æœçš„å‡è¡¡åˆ†å¸ƒï¼Œæ˜¯ä¸€ç§ç®€å•è€Œæœ‰æ•ˆçš„å¤šæºä¿¡æ¯èåˆæ–¹æ³•ã€‚

## ä¸‰ã€è·¯ç”±å†³ç­–é€»è¾‘

æ™ºèƒ½æŸ¥è¯¢è·¯ç”±å™¨é€šè¿‡åˆ†ææŸ¥è¯¢ç‰¹å¾ï¼Œè‡ªåŠ¨é€‰æ‹©æœ€é€‚åˆçš„æ£€ç´¢ç­–ç•¥ï¼š

**å†³ç­–è§„åˆ™**ï¼š
- **ç®€å•æŸ¥è¯¢**ï¼ˆå¤æ‚åº¦ < 0.4ï¼‰â†’ ä¼ ç»Ÿæ··åˆæ£€ç´¢
- **å¤æ‚æ¨ç†æŸ¥è¯¢**ï¼ˆå¤æ‚åº¦ > 0.7 æˆ–å…³ç³»å¯†é›†åº¦ > 0.7ï¼‰â†’ å›¾RAGæ£€ç´¢
- **ä¸­ç­‰å¤æ‚æŸ¥è¯¢**ï¼ˆ0.4 â‰¤ å¤æ‚åº¦ â‰¤ 0.7ï¼‰â†’ ç»„åˆæ£€ç´¢ç­–ç•¥

**è·¯ç”±ç»Ÿè®¡ä¸ä¼˜åŒ–**ï¼š

```python
def _update_route_stats(self, strategy: SearchStrategy):
    """æ›´æ–°è·¯ç”±ç»Ÿè®¡ä¿¡æ¯"""
    self.route_stats["total_queries"] += 1
    if strategy == SearchStrategy.HYBRID_TRADITIONAL:
        self.route_stats["traditional_count"] += 1
    elif strategy == SearchStrategy.GRAPH_RAG:
        self.route_stats["graph_rag_count"] += 1
    elif strategy == SearchStrategy.COMBINED:
        self.route_stats["combined_count"] += 1
```

> æœ€åçš„ç”Ÿæˆéƒ¨åˆ†å°±ä¸è¿‡å¤šèµ˜è¿°äº†ï¼Œå’Œç¬¬å…«ç« ç±»ä¼¼ï¼Œå¯ä»¥è‡ªè¡ŒæŸ¥é˜…ä»£ç ã€‚æœ¬ç« é¡¹ç›®å¹¶ä¸å®Œå–„ï¼Œä»…ä½œä¸ºå¯¹ GraphRAG æµç¨‹å’Œæ¶æ„çš„ç†è§£ã€‚å¯æ ¹æ®å‰é¢æ‰€å­¦å†…å®¹è‡ªè¡Œä¼˜åŒ–ã€‚
