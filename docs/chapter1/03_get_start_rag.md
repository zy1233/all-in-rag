# ç¬¬ä¸‰èŠ‚ å››æ­¥æ„å»ºRAG

é€šè¿‡ç¬¬ä¸€èŠ‚çš„å­¦ä¹ ï¼Œæˆ‘ä»¬å¯¹RAGå·²ç»æœ‰äº†åŸºæœ¬è®¤è¯†ï¼Œå¹¶ä¸”ä¹Ÿå‡†å¤‡å¥½äº†è™šæ‹Ÿç¯å¢ƒå’Œapi_keyï¼Œæ¥ä¸‹æ¥å°†å°è¯•ä½¿ç”¨[**LangChain**](https://python.langchain.com/docs/introduction/)å’Œ[**LlamaIndex**](https://docs.llamaindex.ai/en/stable/)æ¡†æ¶å®Œæˆç¬¬ä¸€ä¸ªRAGåº”ç”¨çš„å®ç°ä¸è¿è¡Œã€‚é€šè¿‡ä¸€ä¸ªç¤ºä¾‹ï¼Œæ¼”ç¤ºå¦‚ä½•åŠ è½½æœ¬åœ°Markdownæ–‡æ¡£ï¼Œåˆ©ç”¨åµŒå…¥æ¨¡å‹å¤„ç†æ–‡æœ¬ï¼Œå¹¶ç»“åˆå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ¥å›ç­”ä¸æ–‡æ¡£å†…å®¹ç›¸å…³çš„é—®é¢˜ã€‚

## ä¸€ã€å¯åŠ¨è™šæ‹Ÿç¯å¢ƒ

### 1.1 æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ

å‡è®¾å·²ç»æŒ‰ç…§å‰ä¸€ç« èŠ‚çš„æŒ‡å¯¼ï¼Œåˆ›å»ºäº†åä¸º `all-in-rag` çš„ Conda è™šæ‹Ÿç¯å¢ƒã€‚åœ¨è¿è¡Œè„šæœ¬å‰ï¼Œå…ˆæ¿€æ´»è™šæ‹Ÿç¯å¢ƒï¼š

> å¦‚æœä½¿ç”¨æ˜¯Cloud Studioï¼Œéœ€è¦ç¡®è®¤å½“å‰æ˜¯å¦æ˜¯ç”¨æˆ·ç¯å¢ƒï¼Œå¦‚æœä¸æ˜¯è¯·è¿è¡Œ `su ubuntu` åˆ‡æ¢åˆ°ç”¨æˆ·ç¯å¢ƒã€‚

```bash
conda activate all-in-rag
```

### 1.2 åˆ‡æ¢åˆ°é¡¹ç›®ç›®å½•

```bash
# å‡è®¾å½“å‰åœ¨ all-in-rag é¡¹ç›®çš„æ ¹ç›®å½•ä¸‹
cd code/C1
```

æ¯ç« å†…å®¹ä¸­çš„ä»£ç æ–‡ä»¶éƒ½å­˜æ”¾åœ¨ `code/Cx` ç›®å½•ä¸‹ï¼Œå…¶ä¸­ `x` è¡¨ç¤ºç« èŠ‚ç¼–å·ã€‚

## äºŒã€è¿è¡ŒRAGç¤ºä¾‹ä»£ç 

å®Œæˆä¸Šè¿°æ‰€æœ‰è®¾ç½®åï¼Œå°±å¯ä»¥è¿è¡ŒRAGç¤ºä¾‹äº†ã€‚

æ‰“å¼€ç»ˆç«¯ï¼Œç¡®ä¿è™šæ‹Ÿç¯å¢ƒå·²æ¿€æ´»ï¼Œç„¶åæ‰§è¡Œä»¥ä¸‹å‘½ä»¤ï¼š

```bash
python 01_langchain_example.py
```

ä»£ç è¿è¡Œåï¼Œå¯ä»¥çœ‹åˆ°ç±»ä¼¼ä¸‹é¢çš„è¾“å‡ºï¼ˆæ ¼å¼åŒ–åï¼‰ï¼š

```bash
Downloading Model from https://www.modelscope.cn to directory: Path\to\all-in-rag\models\bge-small-zh-v1.5
2025-06-08 02:36:19,318 - modelscope - INFO - Target directory already exists, skipping creation.
content='
æ–‡ä¸­ä¸¾äº†ä»¥ä¸‹ä¾‹å­ï¼š

1. **è‡ªç„¶ç•Œä¸­çš„ç¾šç¾Š**ï¼šåˆšå‡ºç”Ÿçš„ç¾šç¾Šé€šè¿‡è¯•é”™å­¦ä¹ ç«™ç«‹å’Œå¥”è·‘ï¼Œé€‚åº”ç¯å¢ƒã€‚
2. **è‚¡ç¥¨äº¤æ˜“**ï¼šé€šè¿‡ä¹°å–è‚¡ç¥¨å¹¶æ ¹æ®å¸‚åœºåé¦ˆè°ƒæ•´ç­–ç•¥ï¼Œæœ€å¤§åŒ–å¥–åŠ±ã€‚
3. **é›…è¾¾åˆ©æ¸¸æˆï¼ˆå¦‚Breakoutå’ŒPongï¼‰**ï¼šé€šè¿‡ä¸æ–­è¯•é”™å­¦ä¹ å¦‚ä½•é€šå…³æˆ–èµ¢å¾—æ¸¸æˆã€‚
4. **é€‰æ‹©é¤é¦†**ï¼šåˆ©ç”¨ï¼ˆå»å·²çŸ¥å–œæ¬¢çš„é¤é¦†ï¼‰ä¸æ¢ç´¢ï¼ˆå°è¯•æ–°é¤é¦†ï¼‰çš„æƒè¡¡ã€‚
5. **åšå¹¿å‘Š**ï¼šåˆ©ç”¨ï¼ˆé‡‡å–å·²çŸ¥æœ€ä¼˜å¹¿å‘Šç­–ç•¥ï¼‰ä¸æ¢ç´¢ï¼ˆå°è¯•æ–°å¹¿å‘Šç­–ç•¥ï¼‰ã€‚
6. **æŒ–æ²¹**ï¼šåˆ©ç”¨ï¼ˆåœ¨å·²çŸ¥åœ°ç‚¹æŒ–æ²¹ï¼‰ä¸æ¢ç´¢ï¼ˆåœ¨æ–°åœ°ç‚¹æŒ–æ²¹ï¼Œå¯èƒ½å‘ç°å¤§æ²¹ç”°ï¼‰ã€‚
7. **ç©æ¸¸æˆï¼ˆå¦‚ã€Šè¡—å¤´éœ¸ç‹ã€‹ï¼‰**ï¼šåˆ©ç”¨ï¼ˆå›ºå®šç­–ç•¥å¦‚è¹²è§’è½å‡ºè„šï¼‰ä¸æ¢ç´¢ï¼ˆå°è¯•æ–°æ‹›å¼å¦‚â€œå¤§æ‹›â€ï¼‰ã€‚

è¿™äº›ä¾‹å­ç”¨äºè¯´æ˜å¼ºåŒ–å­¦ä¹ ä¸­çš„æ ¸å¿ƒæ¦‚å¿µï¼ˆå¦‚æ¢ç´¢ä¸åˆ©ç”¨ã€å»¶è¿Ÿå¥–åŠ±ç­‰ï¼‰åŠå…¶åœ¨å®é™…åœºæ™¯ä¸­çš„åº”ç”¨ã€‚
'
additional_kwargs={'refusal': None}
response_metadata={
    'token_usage': {
        'completion_tokens': 209,
        'prompt_tokens': 5576,
        'total_tokens': 5785,
        'completion_tokens_details': None,
        'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 5568},
        'prompt_cache_hit_tokens': 5568,
        'prompt_cache_miss_tokens': 8
    },
    'model_name': 'deepseek-chat',
    'system_fingerprint': 'fp_8802369eaa_prod0425fp8',
    'id': '67a0580d-78b1-44d6-bccf-f654ae0e9bba',
    'service_tier': None,
    'finish_reason': 'stop',
    'logprobs': None
}
id='run--919cedcd-771e-4aed-8dfd-cf436795792e-0'
usage_metadata={
    'input_tokens': 5576,
    'output_tokens': 209,
    'total_tokens': 5785,
    'input_token_details': {'cache_read': 5568},
    'output_token_details': {}
}
```

> é¦–æ¬¡è¿è¡Œæ—¶ï¼Œè„šæœ¬ä¼šä¸‹è½½`BAAI/bge-small-zh-v1.5`åµŒå…¥æ¨¡å‹ã€‚

è¾“å‡ºå‚æ•°è§£æï¼š
- **`content`**: è¿™æ˜¯æœ€æ ¸å¿ƒçš„éƒ¨åˆ†ï¼Œå³å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ ¹æ®ä½ çš„é—®é¢˜å’Œæä¾›çš„ä¸Šä¸‹æ–‡ç”Ÿæˆçš„å…·ä½“å›ç­”ã€‚
- **`additional_kwargs`**: åŒ…å«ä¸€äº›é¢å¤–çš„å‚æ•°ï¼Œåœ¨è¿™ä¸ªä¾‹å­ä¸­æ˜¯ `{'refusal': None}`ï¼Œè¡¨ç¤ºæ¨¡å‹æ²¡æœ‰æ‹’ç»å›ç­”ã€‚
- **`response_metadata`**: åŒ…å«äº†å…³äºLLMå“åº”çš„å…ƒæ•°æ®ã€‚
    - `token_usage`: æ˜¾ç¤ºäº†æœ¬æ¬¡è°ƒç”¨æ¶ˆè€—çš„tokenæ•°é‡ï¼ŒåŒ…æ‹¬å®Œæˆï¼ˆcompletion_tokensï¼‰ã€æç¤ºï¼ˆprompt_tokensï¼‰å’Œæ€»é‡ï¼ˆtotal_tokensï¼‰ã€‚
    - `model_name`: ä½¿ç”¨çš„LLMæ¨¡å‹åç§°ï¼Œå½“å‰æ˜¯ `deepseek-chat`ã€‚
    - `system_fingerprint`, `id`, `service_tier`, `finish_reason`, `logprobs`: è¿™äº›æ˜¯æ›´è¯¦ç»†çš„APIå“åº”ä¿¡æ¯ï¼Œä¾‹å¦‚ `finish_reason: 'stop'` è¡¨ç¤ºæ¨¡å‹æ­£å¸¸å®Œæˆäº†ç”Ÿæˆã€‚
- **`id`**: æœ¬æ¬¡è¿è¡Œçš„å”¯ä¸€æ ‡è¯†ç¬¦ã€‚
- **`usage_metadata`**: ä¸ `response_metadata` ä¸­çš„ `token_usage` ç±»ä¼¼ï¼Œæä¾›äº†è¾“å…¥å’Œè¾“å‡ºtokençš„ç»Ÿè®¡ã€‚

## ä¸‰ã€åŸºäºLangChainæ¡†æ¶çš„RAGå®ç°

> åœ¨ç¬¬ä¸€èŠ‚ä¸­ï¼Œæˆ‘ä»¬æåˆ°å››æ­¥æ„å»ºæœ€å°å¯è¡Œç³»ç»Ÿåˆ†åˆ«æ˜¯æ•°æ®å‡†å¤‡ã€ç´¢å¼•æ„å»ºã€æ£€ç´¢ä¼˜åŒ–å’Œç”Ÿæˆé›†æˆã€‚æ¥ä¸‹æ¥å°†å›´ç»•è¿™å››ä¸ªæ–¹é¢æ¥å®ç°ä¸€ä¸ªåŸºäºLangChainæ¡†æ¶çš„RAGåº”ç”¨ã€‚

### 3.1 åˆå§‹åŒ–è®¾ç½®

é¦–å…ˆè¿›è¡ŒåŸºç¡€é…ç½®ï¼ŒåŒ…æ‹¬å¯¼å…¥å¿…è¦çš„åº“ã€åŠ è½½ç¯å¢ƒå˜é‡ä»¥åŠä¸‹è½½åµŒå…¥æ¨¡å‹ã€‚

```python
import os
# os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'
from dotenv import load_dotenv
from langchain_community.document_loaders import TextLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_core.vectorstores import InMemoryVectorStore
from langchain_core.prompts import ChatPromptTemplate
from langchain_deepseek import ChatDeepSeek

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()
```

### 3.2 æ•°æ®å‡†å¤‡ (Data Preparation)

- **åŠ è½½åŸå§‹æ–‡æ¡£**: å…ˆå®šä¹‰Markdownæ–‡ä»¶çš„è·¯å¾„ï¼Œç„¶åä½¿ç”¨`TextLoader`åŠ è½½è¯¥æ–‡ä»¶ä½œä¸ºçŸ¥è¯†æºã€‚
    ```python
    markdown_path = "../../data/C1/markdown/easy-rl-chapter1.md"
    loader = TextLoader(markdown_path)
    docs = loader.load()
    ```
- **æ–‡æœ¬åˆ†å— (Chunking)**: ä¸ºäº†ä¾¿äºåç»­çš„åµŒå…¥å’Œæ£€ç´¢ï¼Œé•¿æ–‡æ¡£è¢«åˆ†å‰²æˆè¾ƒå°çš„ã€å¯ç®¡ç†çš„æ–‡æœ¬å—ï¼ˆchunksï¼‰ã€‚è¿™é‡Œé‡‡ç”¨äº†é€’å½’å­—ç¬¦åˆ†å‰²ç­–ç•¥ï¼Œä½¿ç”¨å…¶é»˜è®¤å‚æ•°è¿›è¡Œåˆ†å—ã€‚å½“ä¸æŒ‡å®šå‚æ•°åˆå§‹åŒ– `RecursiveCharacterTextSplitter()` æ—¶ï¼Œå…¶é»˜è®¤è¡Œä¸ºæ—¨åœ¨æœ€å¤§ç¨‹åº¦ä¿ç•™æ–‡æœ¬çš„è¯­ä¹‰ç»“æ„ï¼š
    - **é»˜è®¤åˆ†éš”ç¬¦ä¸è¯­ä¹‰ä¿ç•™**: æŒ‰é¡ºåºå°è¯•ä½¿ç”¨ä¸€ç³»åˆ—é¢„è®¾çš„åˆ†éš”ç¬¦ `["\n\n" (æ®µè½), "\n" (è¡Œ), " " (ç©ºæ ¼), "" (å­—ç¬¦)]` æ¥é€’å½’åˆ†å‰²æ–‡æœ¬ã€‚è¿™ç§ç­–ç•¥çš„ç›®çš„æ˜¯å°½å¯èƒ½ä¿æŒæ®µè½ã€å¥å­å’Œå•è¯çš„å®Œæ•´æ€§ï¼Œå› ä¸ºå®ƒä»¬é€šå¸¸æ˜¯è¯­ä¹‰ä¸Šæœ€ç›¸å…³çš„æ–‡æœ¬å•å…ƒï¼Œç›´åˆ°æ–‡æœ¬å—è¾¾åˆ°ç›®æ ‡å¤§å°ã€‚
    - **ä¿ç•™åˆ†éš”ç¬¦**: é»˜è®¤æƒ…å†µä¸‹ (`keep_separator=True`)ï¼Œåˆ†éš”ç¬¦æœ¬èº«ä¼šè¢«ä¿ç•™åœ¨åˆ†å‰²åçš„æ–‡æœ¬å—ä¸­ã€‚
    - **é»˜è®¤å—å¤§å°ä¸é‡å **: ä½¿ç”¨å…¶åŸºç±» `TextSplitter` ä¸­å®šä¹‰çš„é»˜è®¤å‚æ•° `chunk_size=4000`ï¼ˆå—å¤§å°ï¼‰å’Œ `chunk_overlap=200`ï¼ˆå—é‡å ï¼‰ã€‚è¿™äº›å‚æ•°ç¡®ä¿æ–‡æœ¬å—ç¬¦åˆé¢„å®šçš„å¤§å°é™åˆ¶ï¼Œå¹¶é€šè¿‡é‡å æ¥å‡å°‘ä¸Šä¸‹æ–‡ä¿¡æ¯çš„ä¸¢å¤±ã€‚
    ```python
    text_splitter = RecursiveCharacterTextSplitter()
    texts = text_splitter.split_documents(docs)
    ```

### 3.3 ç´¢å¼•æ„å»º (Index Construction)

æ•°æ®å‡†å¤‡å®Œæˆåï¼Œæ¥ä¸‹æ¥æ„å»ºå‘é‡ç´¢å¼•ï¼š

- **åˆå§‹åŒ–ä¸­æ–‡åµŒå…¥æ¨¡å‹**: ä½¿ç”¨`HuggingFaceEmbeddings`åŠ è½½ä¹‹å‰åœ¨åˆå§‹åŒ–è®¾ç½®ä¸­ä¸‹è½½çš„ä¸­æ–‡åµŒå…¥æ¨¡å‹ã€‚é…ç½®æ¨¡å‹åœ¨CPUä¸Šè¿è¡Œï¼Œå¹¶å¯ç”¨åµŒå…¥å½’ä¸€åŒ– (`normalize_embeddings: True`)ã€‚
    ```python
    embeddings = HuggingFaceEmbeddings(
        model_name="BAAI/bge-small-zh-v1.5",
        model_kwargs={'device': 'cpu'},
        encode_kwargs={'normalize_embeddings': True}
    )
    ```
- **æ„å»ºå‘é‡å­˜å‚¨**: å°†åˆ†å‰²åçš„æ–‡æœ¬å— (`texts`) é€šè¿‡åˆå§‹åŒ–å¥½çš„åµŒå…¥æ¨¡å‹è½¬æ¢ä¸ºå‘é‡è¡¨ç¤ºï¼Œç„¶åä½¿ç”¨`InMemoryVectorStore`å°†è¿™äº›å‘é‡åŠå…¶å¯¹åº”çš„åŸå§‹æ–‡æœ¬å†…å®¹æ·»åŠ è¿›å»ï¼Œä»è€Œåœ¨å†…å­˜ä¸­æ„å»ºå‡ºä¸€ä¸ªå‘é‡ç´¢å¼•ã€‚
    ```python
    vectorstore = InMemoryVectorStore(embeddings)
    vectorstore.add_documents(texts)
    ```
    è¿™ä¸ªè¿‡ç¨‹å®Œæˆåï¼Œä¾¿æ„å»ºäº†ä¸€ä¸ªå¯ä¾›æŸ¥è¯¢çš„çŸ¥è¯†ç´¢å¼•ã€‚

### 3.4 æŸ¥è¯¢ä¸æ£€ç´¢ (Query and Retrieval)

ç´¢å¼•æ„å»ºå®Œæ¯•åï¼Œä¾¿å¯ä»¥é’ˆå¯¹ç”¨æˆ·é—®é¢˜è¿›è¡ŒæŸ¥è¯¢ä¸æ£€ç´¢ï¼š

- **å®šä¹‰ç”¨æˆ·æŸ¥è¯¢**: è®¾ç½®ä¸€ä¸ªå…·ä½“çš„ç”¨æˆ·é—®é¢˜å­—ç¬¦ä¸²ã€‚
    ```python
    question = "æ–‡ä¸­ä¸¾äº†å“ªäº›ä¾‹å­ï¼Ÿ"
    ```
- **åœ¨å‘é‡å­˜å‚¨ä¸­æŸ¥è¯¢ç›¸å…³æ–‡æ¡£**: ä½¿ç”¨å‘é‡å­˜å‚¨çš„`similarity_search`æ–¹æ³•ï¼Œæ ¹æ®ç”¨æˆ·é—®é¢˜åœ¨ç´¢å¼•ä¸­æŸ¥æ‰¾æœ€ç›¸å…³çš„ `k` (æ­¤å¤„ç¤ºä¾‹ä¸­ `k=3`) ä¸ªæ–‡æœ¬å—ã€‚
    ```python
    retrieved_docs = vectorstore.similarity_search(question, k=3)
    ```
- **å‡†å¤‡ä¸Šä¸‹æ–‡**: å°†æ£€ç´¢åˆ°çš„å¤šä¸ªæ–‡æœ¬å—çš„é¡µé¢å†…å®¹ (`doc.page_content`) åˆå¹¶æˆä¸€ä¸ªå•ä¸€çš„å­—ç¬¦ä¸²ï¼Œå¹¶ä½¿ç”¨åŒæ¢è¡Œç¬¦ (`"\n\n"`) åˆ†éš”å„ä¸ªå—ï¼Œå½¢æˆæœ€ç»ˆçš„ä¸Šä¸‹æ–‡ä¿¡æ¯ (`docs_content`) ä¾›å¤§è¯­è¨€æ¨¡å‹å‚è€ƒã€‚
    ```python
    docs_content = "\n\n".join(doc.page_content for doc in retrieved_docs)
    ```
    > ä½¿ç”¨ `"\n\n"` (åŒæ¢è¡Œç¬¦) è€Œä¸æ˜¯ `"\n"` (å•æ¢è¡Œç¬¦) æ¥è¿æ¥ä¸åŒçš„æ£€ç´¢æ–‡æ¡£å—ï¼Œä¸»è¦æ˜¯ä¸ºäº†åœ¨ä¼ é€’ç»™å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ—¶ï¼Œèƒ½å¤Ÿæ›´æ¸…æ™°åœ°åœ¨è¯­ä¹‰ä¸ŠåŒºåˆ†è¿™äº›ç‹¬ç«‹çš„æ–‡æœ¬ç‰‡æ®µã€‚åŒæ¢è¡Œç¬¦é€šå¸¸ä»£è¡¨æ®µè½çš„ç»“æŸå’Œæ–°æ®µè½çš„å¼€å§‹ï¼Œè¿™ç§æ ¼å¼æœ‰åŠ©äºLLMå°†æ¯ä¸ªå—è§†ä¸ºä¸€ä¸ªç‹¬ç«‹çš„ä¸Šä¸‹æ–‡æ¥æºï¼Œä»è€Œæ›´å¥½åœ°ç†è§£å’Œåˆ©ç”¨è¿™äº›ä¿¡æ¯æ¥ç”Ÿæˆå›ç­”ã€‚

### 3.5 ç”Ÿæˆé›†æˆ (Generation Integration)

æœ€åä¸€æ­¥æ˜¯å°†æ£€ç´¢åˆ°çš„ä¸Šä¸‹æ–‡ä¸ç”¨æˆ·é—®é¢˜ç»“åˆï¼Œåˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ç”Ÿæˆç­”æ¡ˆï¼š

- **æ„å»ºæç¤ºè¯æ¨¡æ¿**: ä½¿ç”¨`ChatPromptTemplate.from_template`åˆ›å»ºä¸€ä¸ªç»“æ„åŒ–çš„æç¤ºæ¨¡æ¿ã€‚æ­¤æ¨¡æ¿æŒ‡å¯¼LLMæ ¹æ®æä¾›çš„ä¸Šä¸‹æ–‡ (`context`) å›ç­”ç”¨æˆ·çš„é—®é¢˜ (`question`)ï¼Œå¹¶æ˜ç¡®æŒ‡å‡ºåœ¨ä¿¡æ¯ä¸è¶³æ—¶åº”å¦‚ä½•å›åº”ã€‚
    ```python
    prompt = ChatPromptTemplate.from_template("""è¯·æ ¹æ®ä¸‹é¢æä¾›çš„ä¸Šä¸‹æ–‡ä¿¡æ¯æ¥å›ç­”é—®é¢˜ã€‚
    è¯·ç¡®ä¿ä½ çš„å›ç­”å®Œå…¨åŸºäºè¿™äº›ä¸Šä¸‹æ–‡ã€‚
    å¦‚æœä¸Šä¸‹æ–‡ä¸­æ²¡æœ‰è¶³å¤Ÿçš„ä¿¡æ¯æ¥å›ç­”é—®é¢˜ï¼Œè¯·ç›´æ¥å‘ŠçŸ¥ï¼šâ€œæŠ±æ­‰ï¼Œæˆ‘æ— æ³•æ ¹æ®æä¾›çš„ä¸Šä¸‹æ–‡æ‰¾åˆ°ç›¸å…³ä¿¡æ¯æ¥å›ç­”æ­¤é—®é¢˜ã€‚â€
    
    ä¸Šä¸‹æ–‡:
    {context}
    
    é—®é¢˜: {question}
    
    å›ç­”:"""
                                              )
    ```
- **é…ç½®å¤§è¯­è¨€æ¨¡å‹**: åˆå§‹åŒ–`ChatDeepSeek`å®¢æˆ·ç«¯ï¼Œé…ç½®æ‰€ç”¨æ¨¡å‹ (`deepseek-chat`)ã€ç”Ÿæˆç­”æ¡ˆçš„æ¸©åº¦å‚æ•° (`temperature=0.7`)ã€æœ€å¤§Tokenæ•° (`max_tokens=2048`) ä»¥åŠAPIå¯†é’¥ (ä»ç¯å¢ƒå˜é‡åŠ è½½)ã€‚
    ```python
    llm = ChatDeepSeek(
        model="deepseek-chat",
        temperature=0.7,
        max_tokens=2048,
        api_key=os.getenv("DEEPSEEK_API_KEY")
    )
    ```
- **è°ƒç”¨LLMç”Ÿæˆç­”æ¡ˆå¹¶è¾“å‡º**: å°†ç”¨æˆ·é—®é¢˜ (`question`) å’Œå…ˆå‰å‡†å¤‡å¥½çš„ä¸Šä¸‹æ–‡ (`docs_content`) æ ¼å¼åŒ–åˆ°æç¤ºæ¨¡æ¿ä¸­ï¼Œç„¶åè°ƒç”¨ChatDeepSeekçš„`invoke`æ–¹æ³•è·å–ç”Ÿæˆçš„ç­”æ¡ˆã€‚
    ```python
    answer = llm.invoke(prompt.format(question=question, context=docs_content))
    print(answer)
    ```
[å®Œæ•´ä»£ç ](https://github.com/datawhalechina/all-in-rag/blob/main/code/C1/01_langchain_example.py)

> è€æ¹¿è€æ¹¿ï¼ŒLangchainå¾ˆå¼ºå¤§ä½†è¿˜æ˜¯å¤ªåƒæ“ä½œäº†ï¼Œæœ‰æ²¡æœ‰æ›´åŠ ç®€å•åˆå¥½ç”¨çš„æ¡†æ¶æ¨èå‘¢ï¼Ÿ

> æœ‰çš„å…„å¼Ÿï¼Œæœ‰çš„ï¼åƒè¿™æ ·å¥½ç”¨çš„æ¡†æ¶è¿˜æœ‰LlamaIndexğŸ˜‰

## å››ã€ä½ä»£ç ï¼ˆåŸºäºLlamaIndexï¼‰

> è‹¥å‡ºç°nltkç›¸å…³æŠ¥é”™ï¼Œå°è¯•è¿è¡Œä»£ç è·¯å¾„ä¸‹[fix_nltk.py](https://github.com/datawhalechina/all-in-rag/blob/main/code/C1/fix_nltk.py)

åœ¨RAGæ–¹é¢ï¼ŒLlamaIndexæä¾›äº†æ›´å¤šå°è£…å¥½çš„APIæ¥å£ï¼Œè¿™æ— ç–‘é™ä½äº†ä¸Šæ‰‹é—¨æ§›ï¼Œä¸‹é¢æ˜¯ä¸€ä¸ªç®€å•å®ç°ï¼š

```python
import os
# os.environ['HF_ENDPOINT']='https://hf-mirror.com'
from dotenv import load_dotenv
from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, Settings 
from llama_index.llms.deepseek import DeepSeek
from llama_index.embeddings.huggingface import HuggingFaceEmbedding

load_dotenv()

Settings.llm = DeepSeek(model="deepseek-chat", api_key=os.getenv("DEEPSEEK_API_KEY"))
Settings.embed_model = HuggingFaceEmbedding("BAAI/bge-small-zh-v1.5")

documents = SimpleDirectoryReader(input_files=["../../data/C1/markdown/easy-rl-chapter1.md"]).load_data()

index = VectorStoreIndex.from_documents(documents)

query_engine = index.as_query_engine()

print(query_engine.get_prompts())

print(query_engine.query("æ–‡ä¸­ä¸¾äº†å“ªäº›ä¾‹å­?"))
```

## ç»ƒä¹ ï¼ˆå¯åˆ©ç”¨å¤§æ¨¡å‹è¾…åŠ©å®Œæˆï¼‰

- ä¿®æ”¹Langchainä»£ç ä¸­`RecursiveCharacterTextSplitter()`çš„å‚æ•°`chunk_size`å’Œ`chunk_overlap`ï¼Œè§‚å¯Ÿè¾“å‡ºç»“æœæœ‰ä»€ä¹ˆå˜åŒ–ã€‚
- LangChainä»£ç æœ€ç»ˆå¾—åˆ°çš„è¾“å‡ºæºå¸¦äº†å„ç§å‚æ•°ï¼ŒæŸ¥è¯¢ç›¸å…³èµ„æ–™å°è¯•æŠŠè¿™äº›å‚æ•°è¿‡æ»¤æ‰å¾—åˆ°`content`é‡Œçš„å…·ä½“å›ç­”ã€‚
- ç»™LlamaIndexä»£ç æ·»åŠ ä»£ç æ³¨é‡Šã€‚